{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.preprocessing import image\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.metrics import Precision, Recall, BinaryAccuracy, FalseNegatives, FalsePositives, TrueNegatives, TruePositives\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Individual Splits\n",
    "train_generator = ImageDataGenerator(rotation_range=90,\n",
    "                                     brightness_range=[0.1, 0.7],\n",
    "                                     width_shift_range=0.5, \n",
    "                                     height_shift_range=0.5,\n",
    "                                     horizontal_flip=True,\n",
    "                                     validation_split=0.111,                                      \n",
    "                                     vertical_flip=True,                                    \n",
    "                                     preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
    "\n",
    "valid_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
    "\n",
    "train_data_dir = 'Combined_Manual_Split\\\\train_combined'\n",
    "test_data_dir = 'Combined_Manual_Split\\\\test_combined'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "traingen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               subset='training',\n",
    "                                               batch_size=32, \n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "validgen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               subset='validation',\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_generator.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(224, 224),\n",
    "                                             class_mode=None,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimiser, fine_tune):\n",
    "\n",
    "    #Design CNN Model\n",
    "    base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape= (224,224,3),\n",
    "    include_top=False)\n",
    "\n",
    "\n",
    "\n",
    "    if fine_tune > 0:\n",
    "        base_model.trainable = True\n",
    "    else:\n",
    "        base_model.trainable = False\n",
    "\n",
    "\n",
    "    #Creating new Top Model\n",
    "\n",
    "    inputs = keras.Input(shape=(224,224,3))\n",
    "    top_model = base_model(inputs,training=False)\n",
    "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    #top_model = Dense(4096, activation='relu')(top_model)\n",
    "    #top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = keras.layers.GlobalAveragePooling2D()(top_model)\n",
    "    top_model = keras.layers.Dropout(0.8)(top_model)\n",
    "    top_model = keras.layers.GaussianNoise(0.5)(top_model)\n",
    "    output_layer = keras.layers.Dense(2,activation='sigmoid')(top_model)\n",
    "\n",
    "    #inputs = base_model.input\n",
    "    model = keras.Model(inputs,output_layer)\n",
    "\n",
    "    model.compile(optimizer=optimiser,\n",
    "            loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "            metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = EarlyStopping(monitor='val_loss',patience=30,verbose=1,mode='min')\n",
    "\n",
    "    #model_save_best = ModelCheckpoint('vgg16_combined.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Model without fine-tuning\n",
    "\n",
    "\n",
    "optimiser = keras.optimizers.Adam()\n",
    "fine_tune=0\n",
    "\n",
    "\n",
    "vgg_model = create_model(optimiser, fine_tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model on data\n",
    "epochs = 50\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath=(os.path.join('NoFineTuned_VGG16_Models','noft_VGG16_combined_50epoch.hdf5')),\n",
    "                                  monitor = 'val_loss',\n",
    "                                  mode = 'min',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "\"\"\" lr_adjust = tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=1, verbose=0, mode=\"auto\",\n",
    "    min_delta=0.0001,  cooldown=0,  min_lr=0)         \n",
    " \"\"\"\n",
    "hist = vgg_model.fit(traingen, epochs=epochs,batch_size=32, validation_data=validgen,callbacks=[tl_checkpoint_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.savefig('noft_vgg16_combined_loss_50epoch.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['binary_accuracy'], color='teal', label='binary_accuracy')\n",
    "plt.plot(hist.history['val_binary_accuracy'], color='orange', label='val_binary_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.savefig('noft_vgg16_combined_acc_50epoch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='VGG16_Results\\Epoch Tuning\\Long_runs\\thousandepochs'\n",
    "iterations = 'r1_100epoch'\n",
    "dataset = '_combined'\n",
    "\n",
    "acc_image_name = '\\VGG16_accuracy_'+iterations+dataset+'.png'\n",
    "loss_image_name ='\\VGG16_losses_'+iterations+dataset+'.png'\n",
    "acc_string='vgg16_acc_'+iterations+dataset+'.csv'\n",
    "vacc_string='vgg16_vacc_'+iterations+dataset+'.csv'\n",
    "loss_string ='vgg16_loss_'+iterations+dataset+'.csv'\n",
    "vloss_string='vgg16_vloss_'+iterations+dataset+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export model history data\n",
    "model_acc = pd.DataFrame(hist.history['binary_accuracy'])\n",
    "#model_acc.to_csv(acc_string,header=False,index=False)\n",
    "model_acc.to_csv(acc_string,header=False,index=False)\n",
    "\n",
    "model_val_acc = pd.DataFrame(hist.history['val_binary_accuracy'])\n",
    "#model_val_acc.to_csv(vacc_string,header=False,index=False)\n",
    "model_val_acc.to_csv(vacc_string,header=False,index=False)\n",
    "\n",
    "model_loss = pd.DataFrame(hist.history['loss'])\n",
    "#model_loss.to_csv(loss_string,header=False,index=False)\n",
    "model_loss.to_csv(loss_string,header=False,index=False)\n",
    "\n",
    "model_val_loss = pd.DataFrame(hist.history['val_loss'])\n",
    "#model_val_loss.to_csv(vloss_string,header=False,index=False)\n",
    "model_val_loss.to_csv(vloss_string,header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions\n",
    "vgg_model.load_weights('NoFineTuned_VGG16_Models\\\\noft_VGG16_combined_50epoch.hdf5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds = vgg_model.predict(testgen)\n",
    "vgg_pred_classes = np.argmax(vgg_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes)\n",
    "vgg_recall = recall_score(true_classes, vgg_pred_classes)\n",
    "vgg_f1 = f1_score(true_classes, vgg_pred_classes)\n",
    "vgg_precision = precision_score(true_classes, vgg_pred_classes)\n",
    "\n",
    "print(\"VGG16 Model Accuracy without Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))\n",
    "print(\"VGG16 Model Recall without Fine-Tuning: {:.2f}%\".format(vgg_recall * 100))\n",
    "print(\"VGG16 Model Precision without Fine-Tuning: {:.2f}%\".format(vgg_precision * 100))\n",
    "print(\"VGG16 Model F1 Score without Fine-Tuning: {:.2f}%\".format(vgg_f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true=true_classes, y_pred=vgg_pred_classes)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm_plot_labels = ['Damage','No Damage']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "vgg_pred = vgg_model.predict(testgen).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(true_classes, vgg_pred_classes)\n",
    "\n",
    "plt.plot(fpr_keras,tpr_keras)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do fine-tuning on classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' lr_adjust = tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=1, verbose=0, mode=\"auto\",\\n    min_delta=0.00001,  cooldown=0,  min_lr=0)          '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fine-Tune\n",
    "\n",
    "# Reset our image data generators\n",
    "traingen.reset()\n",
    "validgen.reset()\n",
    "testgen.reset()\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Use a smaller learning rate\n",
    "optim_2 = Adam(learning_rate=1e-6)\n",
    "fine_tune=3\n",
    "# Re-compile the model, this time leaving the last 2 layers unfrozen for Fine-Tuning\n",
    "vgg_model_ft = create_model(optim_2 ,fine_tune)\n",
    "\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath=(os.path.join('Fine_Tuned_Models_VGG16','ft_vgg16_combined_100epoch.hdf5')),\n",
    "                                  monitor = 'val_loss',\n",
    "                                  mode = 'min',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "\"\"\" lr_adjust = tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=1, verbose=0, mode=\"auto\",\n",
    "    min_delta=0.00001,  cooldown=0,  min_lr=0)          \"\"\"                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with fine-tuning\n",
    "epochs =100\n",
    "hist_ft = vgg_model_ft.fit(traingen, epochs=epochs,batch_size=32, validation_data=validgen,callbacks=[tl_checkpoint_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist_ft.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist_ft.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.savefig('ft_vgg16_combined_loss_100epoch.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(hist_ft.history['binary_accuracy'], color='teal', label='binary_accuracy')\n",
    "plt.plot(hist_ft.history['val_binary_accuracy'], color='orange', label='val_binary_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.savefig('ft_vgg16_combined_acc_100epoch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='VGG16_Results\\Epoch Tuning\\Long_runs\\thousandepochs'\n",
    "iterations = 'ft_100epoch'\n",
    "dataset = '_combined'\n",
    "\n",
    "acc_image_name = '\\VGG16_accuracy_'+iterations+dataset+'.png'\n",
    "loss_image_name ='\\VGG16_losses_'+iterations+dataset+'.png'\n",
    "acc_string='vgg16_acc_'+iterations+dataset+'.csv'\n",
    "vacc_string='vgg16_vacc_'+iterations+dataset+'.csv'\n",
    "loss_string ='vgg16_loss_'+iterations+dataset+'.csv'\n",
    "vloss_string='vgg16_vloss_'+iterations+dataset+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export model history data\n",
    "model_acc = pd.DataFrame(hist_ft.history['binary_accuracy'])\n",
    "#model_acc.to_csv(acc_string,header=False,index=False)\n",
    "model_acc.to_csv(acc_string,header=False,index=False)\n",
    "\n",
    "model_val_acc = pd.DataFrame(hist_ft.history['val_binary_accuracy'])\n",
    "#model_val_acc.to_csv(vacc_string,header=False,index=False)\n",
    "model_val_acc.to_csv(vacc_string,header=False,index=False)\n",
    "\n",
    "model_loss = pd.DataFrame(hist_ft.history['loss'])\n",
    "#model_loss.to_csv(loss_string,header=False,index=False)\n",
    "model_loss.to_csv(loss_string,header=False,index=False)\n",
    "\n",
    "model_val_loss = pd.DataFrame(hist_ft.history['val_loss'])\n",
    "#model_val_loss.to_csv(vloss_string,header=False,index=False)\n",
    "model_val_loss.to_csv(vloss_string,header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 images belonging to 2 classes.\n",
      "206/206 [==============================] - 1s 6ms/step\n",
      "VGG16 Model Accuracy with Fine-Tuning: 91.26%\n",
      "VGG16 Model Recall with Fine-Tuning: 97.00%\n",
      "VGG16 Model Precision with Fine-Tuning: 86.61%\n",
      "VGG16 Model F1 Score with Fine-Tuning: 91.51%\n"
     ]
    }
   ],
   "source": [
    "#Generate predictions on piezo set\n",
    "test_data_dir_piezo = 'Combined_Manual_Split\\\\test_combined'\n",
    "\n",
    "testgen = test_generator.flow_from_directory(test_data_dir_piezo,\n",
    "                                             target_size=(224, 224),\n",
    "                                             class_mode=None,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vgg_model_ft.load_weights('Fine_Tuned_Models_VGG16\\\\ft_vgg16_combined_100epoch.hdf5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds_ft = vgg_model_ft.predict(testgen)\n",
    "vgg_pred_classes_ft = np.argmax(vgg_preds_ft, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes_ft)\n",
    "vgg_recall = recall_score(true_classes, vgg_pred_classes_ft)\n",
    "vgg_f1 = f1_score(true_classes, vgg_pred_classes_ft)\n",
    "vgg_precision = precision_score(true_classes, vgg_pred_classes_ft)\n",
    "\n",
    "print(\"VGG16 Model Accuracy with Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))\n",
    "print(\"VGG16 Model Recall with Fine-Tuning: {:.2f}%\".format(vgg_recall * 100))\n",
    "print(\"VGG16 Model Precision with Fine-Tuning: {:.2f}%\".format(vgg_precision * 100))\n",
    "print(\"VGG16 Model F1 Score with Fine-Tuning: {:.2f}%\".format(vgg_f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "vgg_model_ft.load_weights('Fine_Tuned_Models_VGG16\\\\ft_vgg16_combined_100epoch.hdf5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds_ft = vgg_model_ft.predict(testgen)\n",
    "vgg_pred_classes_ft = np.argmax(vgg_preds_ft, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes_ft)\n",
    "vgg_recall = recall_score(true_classes, vgg_pred_classes_ft)\n",
    "vgg_f1 = f1_score(true_classes, vgg_pred_classes_ft)\n",
    "vgg_precision = precision_score(true_classes, vgg_pred_classes_ft)\n",
    "\n",
    "print(\"VGG16 Model Accuracy with Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))\n",
    "print(\"VGG16 Model Recall with Fine-Tuning: {:.2f}%\".format(vgg_recall * 100))\n",
    "print(\"VGG16 Model Precision with Fine-Tuning: {:.2f}%\".format(vgg_precision * 100))\n",
    "print(\"VGG16 Model F1 Score with Fine-Tuning: {:.2f}%\".format(vgg_f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true=true_classes, y_pred=vgg_pred_classes_ft)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm_plot_labels = ['Damage','No Damage']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0c8fbc65871ee6e07cf80d6b5377575afbb2900957f14e1f6702a6d9dd14c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
